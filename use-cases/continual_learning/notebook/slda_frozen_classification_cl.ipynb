{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00b2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2024 Intel Corporation.\n",
    "#\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4320e5",
   "metadata": {},
   "source": [
    "# Tutorial: Using SLDA to simulate Continual Learning Scenarios\n",
    "## With a frozen pretrained feature extractor\n",
    "Streaming Linear Discriminant Analysis (SLDA), is a type of generative model that learns a linear classifier over precomputed features from a frozen feature extractor.\n",
    "\n",
    "SLDA learns a per-class Gaussian distribution with covariance matrix that is shared across all classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd6b2e-41f3-40f1-89d2-634caca93731",
   "metadata": {},
   "source": [
    "## Start from home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "365cc5be-71d2-4a34-8128-53a516a7b97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sabrepc/AI/train/cldemo/test012624/frameworks.ai.algorithms.continual-learning.ebm\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb8a37",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf886d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sabrepc/AI/train/cldemo/test012624/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-27 08:56:03.362386: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-01-27 08:56:03.362403: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-01-27 08:56:03.362643: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Config/Options\n",
    "from config import Decoders\n",
    "from config import IMG_AUGMENT_LAYERS\n",
    "\n",
    "# Model/Loss definitions\n",
    "from model.slda import SLDA\n",
    "from model import losses\n",
    "from model.utils import extract_features\n",
    "\n",
    "# Dataset handling (synthesize/build/query)\n",
    "from lib.dataset.repository import DatasetRepository\n",
    "from lib.dataset.utils import as_tuple, decode_example, get_label_distribution\n",
    "from lib.dataset.synthesizer import synthesize_by_sharding_over_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ade995f",
   "metadata": {},
   "source": [
    "### Experiment Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0304ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = '../../../dataset/oxford_flowers102'  # loading a local TFRecord dataset\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER = 16384\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ed4d6b",
   "metadata": {},
   "source": [
    "### Load the *entire* Dataset\n",
    "We deal with `tf.data.Dataset` APIs for all our simulations.\n",
    "\n",
    "The additional argument to note here, is the `decoders`. We supply our custom `Decoders.SIMPLE_DECODER` that partially decodes the data for two main reasons:\n",
    "1. It only parses `image` and `label` keys from the dataset (we're only dealing with classification problems here).\n",
    "2. It 'skips' decoding the images to tensors (hence you see it as `tf.string` type). This is for performance reasons. As you'll see, we decode it when we build our data pipeline for training/testing on-the-fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ae70763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About:  tfds.core.DatasetInfo(\n",
      "    name='oxford_flowers102',\n",
      "    full_name='oxford_flowers102/2.1.1',\n",
      "    description=\"\"\"\n",
      "    The Oxford Flowers 102 dataset is a consistent of 102 flower categories commonly occurring\n",
      "    in the United Kingdom. Each class consists of between 40 and 258 images. The images have\n",
      "    large scale, pose and light variations. In addition, there are categories that have large\n",
      "    variations within the category and several very similar categories.\n",
      "    \n",
      "    The dataset is divided into a training set, a validation set and a test set.\n",
      "    The training set and validation set each consist of 10 images per class (totalling 1020 images each).\n",
      "    The test set consists of the remaining 6149 images (minimum 20 per class).\n",
      "    \n",
      "    Note: The dataset by default comes with a test size larger than the train\n",
      "    size. For more info see this [issue](https://github.com/tensorflow/datasets/issues/3022).\n",
      "    \"\"\",\n",
      "    homepage='https://www.robots.ox.ac.uk/~vgg/data/flowers/102/',\n",
      "    data_path='../../../dataset/oxford_flowers102/2.1.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=328.90 MiB,\n",
      "    dataset_size=331.34 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'file_name': Text(shape=(), dtype=tf.string),\n",
      "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=102),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': MultiSplitInfo(name='test', split_infos=[<SplitInfo num_examples=6149, num_shards=2>]),\n",
      "        'train': MultiSplitInfo(name='train', split_infos=[<SplitInfo num_examples=1020, num_shards=1>]),\n",
      "        'validation': MultiSplitInfo(name='validation', split_infos=[<SplitInfo num_examples=1020, num_shards=1>]),\n",
      "    },\n",
      "    citation=\"\"\"@InProceedings{Nilsback08,\n",
      "       author = \"Nilsback, M-E. and Zisserman, A.\",\n",
      "       title = \"Automated Flower Classification over a Large Number of Classes\",\n",
      "       booktitle = \"Proceedings of the Indian Conference on Computer Vision, Graphics and Image Processing\",\n",
      "       year = \"2008\",\n",
      "       month = \"Dec\"\n",
      "    }\"\"\",\n",
      ")\n",
      "Element Spec:  {'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}\n",
      "Training samples:  1020\n",
      "Testing samples:  6149\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Load the dataset: Public or Local\"\"\"\n",
    "if tf.io.gfile.isdir(DATASET):\n",
    "    repo = DatasetRepository(data_dir=DATASET)\n",
    "    builder = repo.get_builder()  # Builds all versions by default\n",
    "    ds_info = builder.info\n",
    "    (raw_train_ds, raw_test_ds) = builder.as_dataset(split=['train', 'test'],\n",
    "                                                     decoders=Decoders.SIMPLE_DECODER)\n",
    "else:\n",
    "    # Load TFDS dataset by name (publicly-hosted on TF)\n",
    "    (raw_train_ds, raw_test_ds), ds_info = tfds.load(DATASET,\n",
    "                                                     split=['train', 'test'],\n",
    "                                                     with_info=True,\n",
    "                                                     decoders=Decoders.SIMPLE_DECODER)\n",
    "print('About: ', ds_info)\n",
    "print('Element Spec: ', raw_train_ds.element_spec)\n",
    "print('Training samples: ', len(raw_train_ds))\n",
    "print('Testing samples: ', len(raw_test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1477d9a",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "Let's choose a pretrained backbone to extract features. Since in this experiment we keep the backbone frozen and finetune only a few additional layers, it is much faster to iterate if we compute all features of all images at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce27ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feature_extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " augment_layers (Sequential)  (None, 224, 224, 3)      0         \n",
      "                                                                 \n",
      " efficientnetv2-b0 (Function  (None, 1280)             5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,919,312\n",
      "Trainable params: 0\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Choose Model backbone to extract features\"\"\"\n",
    "backbone = tf.keras.applications.EfficientNetV2B0(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(*IMG_SIZE, 3),\n",
    "    pooling='avg'\n",
    ")\n",
    "backbone.trainable = False\n",
    "\n",
    "\"\"\"Add augmentation/input layers\"\"\"\n",
    "feature_extractor = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(backbone.input_shape[1:]),\n",
    "    IMG_AUGMENT_LAYERS,\n",
    "    backbone,\n",
    "], name='feature_extractor')\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f786c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train set features\n",
      "32/32 [==============================] - 7s 171ms/step\n",
      "Extracting test set features\n",
      "193/193 [==============================] - 32s 164ms/step\n",
      "Features Dataset spec:  {'image': TensorSpec(shape=(1280,), dtype=tf.float32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Extract train/test feature embeddings\"\"\"\n",
    "print(f'Extracting train set features')\n",
    "train_features = extract_features(dataset=(raw_train_ds\n",
    "                                        .map(decode_example(IMG_SIZE))\n",
    "                                        .map(as_tuple(x='image', y='label'))\n",
    "                                        .batch(BATCH_SIZE)\n",
    "                                        .prefetch(tf.data.AUTOTUNE)), model=feature_extractor)\n",
    "print(f'Extracting test set features')\n",
    "test_features = extract_features(dataset=(raw_test_ds\n",
    "                                        .map(decode_example(IMG_SIZE))\n",
    "                                        .map(as_tuple(x='image', y='label'))\n",
    "                                        .batch(BATCH_SIZE)\n",
    "                                        .prefetch(tf.data.AUTOTUNE)), model=feature_extractor)\n",
    "print('Features Dataset spec: ', train_features.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c3174",
   "metadata": {},
   "source": [
    "### Creating a Continual Learning Dataset\n",
    "Now that we have the extracted features, we would like to partition this entire training set into `n` parts, to train our model sequentially, without access to older data.\n",
    "\n",
    "Each partition holds data from only a selected few classes. In literature, this is known as the 'Class Incremental Learning' setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74243f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitions: 5\n",
      "Partition 0: {5: 10, 8: 10, 9: 10, 10: 10, 11: 10, 13: 10, 16: 10, 20: 10, 27: 10, 36: 10, 37: 10, 39: 10, 55: 10, 67: 10, 82: 10, 84: 10, 85: 10, 87: 10, 95: 10, 96: 10, 99: 10}\n",
      "Partition 1: {4: 10, 19: 10, 22: 10, 23: 10, 25: 10, 34: 10, 42: 10, 44: 10, 52: 10, 66: 10, 68: 10, 72: 10, 74: 10, 75: 10, 79: 10, 81: 10, 83: 10, 88: 10, 92: 10, 100: 10, 101: 10}\n",
      "Partition 2: {1: 10, 2: 10, 3: 10, 6: 10, 15: 10, 17: 10, 18: 10, 21: 10, 24: 10, 28: 10, 30: 10, 35: 10, 43: 10, 50: 10, 53: 10, 57: 10, 65: 10, 70: 10, 89: 10, 93: 10}\n",
      "Partition 3: {0: 10, 12: 10, 26: 10, 32: 10, 40: 10, 45: 10, 46: 10, 47: 10, 49: 10, 51: 10, 60: 10, 61: 10, 62: 10, 64: 10, 71: 10, 80: 10, 86: 10, 94: 10, 97: 10, 98: 10}\n",
      "Partition 4: {7: 10, 14: 10, 29: 10, 31: 10, 33: 10, 38: 10, 41: 10, 48: 10, 54: 10, 56: 10, 58: 10, 59: 10, 63: 10, 69: 10, 73: 10, 76: 10, 77: 10, 78: 10, 90: 10, 91: 10}\n"
     ]
    }
   ],
   "source": [
    "N_PARTITIONS = 5\n",
    "\n",
    "# This returns a dictionary of partitioned datasets, keyed by partition_id, an integer\n",
    "partitioned_dataset = synthesize_by_sharding_over_labels(train_features, \n",
    "                                                         num_partitions=N_PARTITIONS, \n",
    "                                                         shuffle_labels=True)\n",
    "# Check the label counts of each partition\n",
    "print('Partitions:', len(partitioned_dataset))\n",
    "for partition_id in partitioned_dataset:\n",
    "    dist = get_label_distribution(partitioned_dataset[partition_id])\n",
    "    print(f'Partition {partition_id}: {dist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8526a2",
   "metadata": {},
   "source": [
    "### Define an SLDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd85893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLDA takes a feature vector, linearly maps it to the output class\n",
    "model = SLDA(n_components=feature_extractor.output_shape[-1],\n",
    "             num_classes=ds_info.features['label'].num_classes)\n",
    "\n",
    "# Compile. No loss/optimizer since it is a gradient-free algorithm\n",
    "model.compile(metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730c4d9",
   "metadata": {},
   "source": [
    "### Train SLDA Model sequentially over each Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daf22d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training [1/5]\n",
      "211/211 [==============================] - 3s 14ms/step - val_accuracy: 0.1573\n",
      "Training [2/5]\n",
      "211/211 [==============================] - 2s 12ms/step - val_accuracy: 0.3438\n",
      "Training [3/5]\n",
      "201/201 [==============================] - 2s 12ms/step - val_accuracy: 0.4863\n",
      "Training [4/5]\n",
      "201/201 [==============================] - 2s 12ms/step - val_accuracy: 0.6681\n",
      "Training [5/5]\n",
      "201/201 [==============================] - 2s 12ms/step - val_accuracy: 0.8483\n"
     ]
    }
   ],
   "source": [
    "# Build test dataset pipeline\n",
    "test_ds = (test_features\n",
    "            .cache()\n",
    "            .map(as_tuple(x='image', y='label'))\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "# Incrementally train on each partition\n",
    "for partition_id in partitioned_dataset:\n",
    "\n",
    "    print(f'Training [{partition_id+1}/{len(partitioned_dataset)}]')\n",
    "    \n",
    "    # Build Train Dataset pipeline\n",
    "    train_ds = (partitioned_dataset[partition_id]\n",
    "                .cache()\n",
    "                .shuffle(SHUFFLE_BUFFER)\n",
    "                .map(as_tuple(x='image', y='label'))\n",
    "                .batch(1)  # SLDA learns 1-sample at a time. Inference can be done on batch.\n",
    "                .prefetch(tf.data.AUTOTUNE))\n",
    "    \n",
    "    # SLDA performs well even on a single pass over the dataset\n",
    "    model.fit(train_ds, epochs=1, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5574f61f-ab5f-4533-bbc2-ea0d008474c9",
   "metadata": {},
   "source": [
    "## Measure the Top1 and Top5 testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a52b5ffe-d8de-463b-8faf-72f999edd512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/193 [==============================] - 1s 3ms/step\n",
      "Top-1 Accuracy: 0.8482680110587087\n",
      "Top-5 Accuracy: 0.9409660107334525\n"
     ]
    }
   ],
   "source": [
    "# Collect true labels from the validation dataset\n",
    "true_labels = []\n",
    "for batch in test_ds:\n",
    "    true_labels.extend(batch[1].numpy())  # Assuming labels are in the second element of each batch\n",
    "\n",
    "total_samples = len(true_labels)\n",
    "\n",
    "if total_samples > 0:\n",
    "    predictions = model.predict(test_ds)\n",
    "\n",
    "    top1_correct = 0\n",
    "    top5_correct = 0\n",
    "\n",
    "    for i in range(total_samples):\n",
    "        # Calculate top-1 accuracy\n",
    "        top1_prediction = tf.argmax(predictions[i])\n",
    "        if top1_prediction == true_labels[i]:\n",
    "            top1_correct += 1\n",
    "\n",
    "        # Calculate top-5 accuracy\n",
    "        top5_predictions = tf.nn.top_k(predictions[i], k=5).indices\n",
    "        if true_labels[i] in top5_predictions:\n",
    "            top5_correct += 1\n",
    "\n",
    "    top1_accuracy = top1_correct / total_samples\n",
    "    top5_accuracy = top5_correct / total_samples\n",
    "\n",
    "    print(\"Top-1 Accuracy:\", top1_accuracy)\n",
    "    print(\"Top-5 Accuracy:\", top5_accuracy)\n",
    "else:\n",
    "    print(\"No samples in the validation dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76443161",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Try testing various partition sizes for SLDA. You'll observe the drop in accuracy isn't significant despite multiple tasks.\n",
    "This is due to the generative nature of LDA.\n",
    "\n",
    "By learning per-class Gaussians, class-incremental learning problem becomes task-incremental, making it agnostic of the order of classes during training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
